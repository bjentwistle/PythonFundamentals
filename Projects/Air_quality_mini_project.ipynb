{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Air quality mini-project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bjentwistle/PythonFundamentals/blob/main/Projects/Air_quality_mini_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean and wrangle air quality data\n",
        "\n",
        "The following data file contains data collected at a roadside monitoring station.  You can see the data in a spreadsheet here: https://docs.google.com/spreadsheets/d/1XpAvrpuyMsKDO76EZ3kxuddBOu7cZX1Od4uEts14zco/edit?usp=sharing\n",
        "\n",
        "The data contains:\n",
        "* a heading line (Chatham Roadside) which needs to be skipped\n",
        "* dates which are sometimes left- and sometimes right-justified indicating that they are not formatted as dates, rather they are text (so need to be converted to dates)\n",
        "* times which are not all in the same format\n",
        "* Nitrogen Dioxide levels which are, again, text and sometimes contain nodata\n",
        "* Status which is always the same\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8qnlsapq24Df"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project - clean, sort and wrangle the data\n",
        "\n",
        "Read the dataset into a dataframe, skipping the first row   \n",
        "Convert dates to date format  \n",
        "Remove rows with nodata in the Nitrogen dioxide column  \n",
        "Convert the Nitrogen dioxide levels values to float type  \n",
        "Sort by Nitrogen dioxide level  \n",
        "Create a new column for 'Weekdays' (use df['Date'].dt.weekday)  \n",
        "Rename the column Nitrogen dioxide level to NO2 Level (V ug/m2)  \n",
        "Remove the Status column  \n",
        "\n",
        "The dataset can be viewed here:  https://drive.google.com/file/d/1aYmBf9il2dWA-EROvbYRCZ1rU2t7JwvJ/view?usp=sharing  and the data accessed here: https://drive.google.com/uc?id=1QSNJ3B1ku8kjXsA_tCBh4fbpDK7wVLAA This is a .csv file  \n",
        "\n",
        "**NOTE:** Some useful references are included at the bottom of this spreadsheet.\n",
        "\n",
        "Use the code cell below to work your code."
      ],
      "metadata": {
        "id": "SSvLiFnp4LjG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Expand the dataset and show summary statistics for larger dataset\n",
        "---\n",
        "\n",
        "There is a second data set here covering the year 2021:  https://drive.google.com/uc?id=1aYmBf9il2dWA-EROvbYRCZ1rU2t7JwvJ  \n",
        "\n",
        "Concatenate the two datasets to expand it to 2020 and 2021.  \n",
        "\n",
        "Before you can concatenate the datasets you will need to clean and wrangle the second dataset in the same way as the first.  Use the code cell below.  Give the second dataset a different name. \n",
        "\n",
        "After the datasets have been concatenated, group the data by Weekdays and show summary statistics by day of the week."
      ],
      "metadata": {
        "id": "jnzAnbsmHk4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#read in data for 2021 air quality of Chatham Roadside\n",
        "url = \"https://raw.githubusercontent.com/bjentwistle/PythonFundamentals/main/Datasets/NO2-measured-data-2020-2021-Chatham-Roadside%20-%20NO2-measurement-data-2020-2021.csv\"\n",
        "air_quality_2020 = pd.read_csv(url,skiprows=[0])\n",
        "\n",
        "#remove 'nodata' rows from Nitrogen Dioxide column\n",
        "for i in air_quality_2020.index:\n",
        "  if air_quality_2020.loc[i, \"Nitrogen dioxide\"] == \"nodata\":\n",
        "    air_quality_2020.drop(i, inplace = True) \n",
        "\n",
        "air_quality_2020.dtypes"
      ],
      "metadata": {
        "id": "2KPQVVtonW5R",
        "outputId": "5c492fcd-c429-493b-86d2-d6ed8cbb0c0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b42d7fa8f126>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#read in data for 2021 air quality of Chatham Roadside\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://raw.githubusercontent.com/bjentwistle/PythonFundamentals/main/Datasets/NO2-measured-data-2020-2021-Chatham-Roadside%20-%20NO2-measurement-data-2020-2021.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mair_quality_2020\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#remove 'nodata' rows from Nitrogen Dioxide column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_dtype_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb5 in position 82: invalid start byte"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "air_quality_2020\n",
        "#air_quality_2020['Time'] = pd.to_datetime(air_quality_2020['Time'])"
      ],
      "metadata": {
        "id": "Q6FR9E6Mqa_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert all dates to Datetime format\n",
        "air_quality_2020['Date'] = pd.to_datetime(air_quality_2020['Date'])\n",
        "air_quality_2020['Time'] = pd.to_datetime(air_quality_2020['Time'])\n",
        "\n",
        "#convert Nitrogen dioxide column to float type\n",
        "air_quality_2020['Nitrogen dioxide'] = pd.Float64Index(air_quality_2020['Nitrogen dioxide'])\n",
        "\n",
        "#sort by Nitrogen dioxide\n",
        "air_quality_2020 = air_quality_2020.sort_values(\"Nitrogen dioxide\")\n",
        "\n",
        "#add new column called 'weekdays'\n",
        "air_quality_2020[\"Weekdays\"] = air_quality_2020['Date'].dt.strftime(\"%a\")\n",
        "\n",
        "#rename Nitrogen dioxide column to \"NO2 Level (V ug/m2)\"\n",
        "air_quality_2020.rename(columns = {\"Nitrogen dioxide\":\"NO2 Level (V ug/m2)\"}, inplace =True)\n",
        "\n",
        "#drop the Status column\n",
        "air_quality_2020_v2 = air_quality_2020.drop([\"Status\"],axis=1)\n",
        "\n",
        "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "\n",
        "#read in data for 2021 air quality of Chatham Roadside\n",
        "url =  \"https://raw.githubusercontent.com/bjentwistle/PythonFundamentals/main/Datasets/NO2-measured-data-2021-2022-Chatham-Roadside.csv\"\n",
        "air_quality_2021 = pd.read_csv(url, skiprows=[0])\n",
        "\n",
        "#remove 'nodata' rows from Nitrogen Dioxide column\n",
        "for x in air_quality_2021.index:\n",
        "  if air_quality_2021.loc[x, \"Nitrogen dioxide\"] == \"nodata\":\n",
        "    air_quality_2021.drop(x, inplace = True) \n",
        "\n",
        "#Do the same with 2021 dataset - convert all dates to Datetime format\n",
        "air_quality_2021['Date'] = pd.to_datetime(air_quality_2021['Date'])\n",
        "air_quality_2021['Time'] = pd.to_datetime(air_quality_2021['Time'])\n",
        "\n",
        "#convert Nitrogen dioxide column to float type\n",
        "air_quality_2021['Nitrogen dioxide'] = pd.Float64Index(air_quality_2021['Nitrogen dioxide'])\n",
        "\n",
        "#sort by Nitrogen dioxide\n",
        "air_quality_2021 = air_quality_2021.sort_values(\"Nitrogen dioxide\")\n",
        "\n",
        "#add new column called 'weekdays'\n",
        "air_quality_2021[\"Weekdays\"] = air_quality_2021['Date'].dt.strftime(\"%a\")\n",
        "\n",
        "#rename Nitrogen dioxide column to \"NO2 Level (V ug/m2)\"\n",
        "air_quality_2021.rename(columns = {\"Nitrogen dioxide\":\"NO2 Level (V ug/m2)\"}, inplace =True)\n",
        "\n",
        "#drop the Status column\n",
        "air_quality_2021_v2 = air_quality_2021.drop([\"Status\"],axis=1)\n",
        "\n",
        "print(air_quality_2020_v2)\n",
        "print(air_quality_2021_v2)\n"
      ],
      "metadata": {
        "id": "txM4TIRUHhsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#concatenate the two years of data and sort by date then print as a test\n",
        "combined_df = pd.concat([air_quality_2020_v2, air_quality_2021_v2], join='inner', ignore_index=True)\n",
        "combined_df = combined_df.sort_values(\"Date\")\n",
        "\n",
        "#Calcuate the averages NO2 levels by weekdays (same as pivot below)\n",
        "# average_NO2 = combined_df.groupby([\"Weekdays\"])[\"NO2 Level (V ug/m2)\"].mean()\n",
        "# print(type(average_NO2))\n",
        "\n",
        "#Group by Weekdays and show smmary stats by day of the week\n",
        "air_quality_pivot = pd.pivot_table(combined_df, values = \"NO2 Level (V ug/m2)\", index = [\"Weekdays\"], aggfunc = np.mean)\n",
        "print(air_quality_pivot)\n",
        "\n"
      ],
      "metadata": {
        "id": "Gz4u6trsIQJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10/3/2022 - Update \n",
        "Returning to this project after several week on the Data Accelerator course, I wanted to add some visualisations and possible predictions to this project."
      ],
      "metadata": {
        "id": "E1eUM-LuYij2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# weekday_categories = [\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"]\n",
        "# air_quality_pivot[\"Weekdays\"] = pd.Categorical(air_quality_pivot[\"Weekdays\"], categories = weekday_categories, ordered= True)\n",
        "# #air_quality_pivot.sort_values(\"Weekdays\")\n",
        "# print(air_quality_pivot)\n",
        "#THIS CODE ABOVE DOES NOT WORK DUE TO WEEKDAYS BECOMING THE INDEX AND HENCE CAN\"T BE SORTED CATEGORICALLY\n",
        "sns.set(rc = {'figure.figsize':(10,5)})\n",
        "air_quality_pivot.plot(kind='bar', color = \"green\").legend(bbox_to_anchor=(1.2, 1))\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Qt2ER64oY4Gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot of NO2 levels plotted by the day they were recorded shows very clearly that Sunday is when there are the least number of cars on the road. Conversely, the busiest days of the week have the highest levels of NO2.\n",
        "\n",
        "It would be interesting to see what the levels are like at different times of the day too.\n"
      ],
      "metadata": {
        "id": "ek0BQ6AxmCXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Group by time and show summary stats by day of the week\n",
        "air_quality__time_pivot = pd.pivot_table(combined_df, values = \"NO2 Level (V ug/m2)\", index = [\"Time\"], aggfunc = np.mean)\n",
        "#print(air_quality__time_pivot)\n",
        "sns.set(rc = {'figure.figsize':(20,8)})\n",
        "air_quality__time_pivot.plot(kind='bar', color = \"lightblue\").legend(bbox_to_anchor=(1, 1))\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8tyfolrrmdQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot shows the peak times during the day when the highest levels coincide with 'rush hour' times. "
      ],
      "metadata": {
        "id": "3fM8Eq8woiw3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helpful references\n",
        "---\n",
        "Skipping rows when reading datasets:  \n",
        "https://www.geeksforgeeks.org/how-to-skip-rows-while-reading-csv-file-using-pandas/  \n",
        "\n",
        "Converting strings to dates:  \n",
        "https://www.geeksforgeeks.org/convert-the-column-type-from-string-to-datetime-format-in-pandas-dataframe/\n",
        "\n",
        "Dropping rows where data has a given value:  \n",
        "https://www.datasciencemadesimple.com/drop-delete-rows-conditions-python-pandas/  \n",
        "(see section Drop a row or observation by condition) \n",
        "\n",
        "Convert a column of strings to a column of floats:\n",
        "https://datatofish.com/convert-string-to-float-dataframe/  \n",
        "\n",
        "Create a new column from data converted in an existing column:  \n",
        "https://www.geeksforgeeks.org/create-a-new-column-in-pandas-dataframe-based-on-the-existing-columns/  \n",
        "\n",
        "Rename a column:  \n",
        "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html  \n",
        "\n",
        "Remove a column by name:  \n",
        "https://www.kite.com/python/answers/how-to-delete-columns-from-a-pandas-%60dataframe%60-by-column-name-in-python#:~:text=Use%20the%20del%20keyword%20to,the%20name%20column_name%20from%20DataFrame%20.\n"
      ],
      "metadata": {
        "id": "hkj-Ofus_D6_"
      }
    }
  ]
}