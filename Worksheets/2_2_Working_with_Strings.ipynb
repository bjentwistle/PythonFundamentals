{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.2 Working with Strings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bjentwistle/PythonFundamentals/blob/main/Worksheets/2_2_Working_with_Strings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdT0fwTCa4gI"
      },
      "source": [
        "# Working with Strings\n",
        "---\n",
        "\n",
        "The pandas library has a similar set of string functions to those available in python generally.  Because we often want to perform operations on a whole series of data values in a dataframe, we can use pandas string functions to do this:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a series from a pandas column\n",
        "---\n",
        "\n",
        "A column of data is treated by pandas as a Series.  There is a set of functions that you can access for working with a **series** (just one column from the data table).\n",
        "\n",
        "To get a 'series' from a dataframe, you would split the column from the rest of the dataframe by taking a copy of it and storing it in a new variable (which is very similar to a list).\n",
        "\n",
        "The examples below show what you can do with a Series rather than a whole table.\n",
        "\n",
        "To get a column of data as a series:\n",
        "\n",
        "```\n",
        "series_data = df['date']\n",
        "```\n",
        "or\n",
        "```\n",
        "price_series = df['price']\n",
        "```\n",
        "where 'date' or 'price' are the names of the columns in the dataframe"
      ],
      "metadata": {
        "id": "GEi6lFzV2dAa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozWLM6Pfa7d_"
      },
      "source": [
        "### Splitting data \n",
        "---\n",
        "\n",
        "Series.str.split() *to split a column's strings into components*    \n",
        "Series.str.get() *to get one of the components after the split*  \n",
        "\n",
        "You can **daisychain** these together:   \n",
        "\n",
        "`Series.str.split().str.get()`\n",
        "\n",
        "* `split()` will split by white space unless specified, for example if you wanted to split by \"/\" you would use `split(\"/\")`  \n",
        "\n",
        "* `get()` requires a parameter of the value position of the string you would like to 'get'. If you want the first word eg 1999, use `get(0)`.\n",
        "\n",
        "\n",
        "*Hint: remember to save your result into a new column* \n",
        "\n",
        "### Exercise 1 strings\n",
        "---\n",
        "\n",
        "Let's use the data set 'Housing in London' at 'https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv'\n",
        "\n",
        "The date, in this dataset is a string.   To filter for a particular year, we will need to extract the first four letters as a substring.  We can create a new column called **year**, which just contains the year, stored as a number.\n",
        "\n",
        "The date is written in the format yyyy-mm-dd.  We can split the year around the '-' and then use the first component.\n",
        "\n",
        "\n",
        "Create a function called **get_year()** which splits the data from the date column, and creates a year column with just the year before returning the year column.\n",
        "\n",
        "\n",
        "**Test output**:  \n",
        "\n",
        "```\n",
        "0       1999\n",
        "1       1999\n",
        "2       1999\n",
        "3       1999\n",
        "4       1999\n",
        "        ... \n",
        "1066    2019\n",
        "1067    2019\n",
        "1068    2019\n",
        "1069    2019\n",
        "1070    2019\n",
        "Name: year, Length: 1071, dtype: object\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv'\n",
        "dataset = pd.read_csv(url)\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "2MvfiiC_gSGN",
        "outputId": "c69c215b-1a4d-45c4-83ed-dbc20fda52c3"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-162941a5-ff50-4aad-9b06-335c19198b5b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>area</th>\n",
              "      <th>date</th>\n",
              "      <th>median_salary</th>\n",
              "      <th>life_satisfaction</th>\n",
              "      <th>mean_salary</th>\n",
              "      <th>recycling_pct</th>\n",
              "      <th>population_size</th>\n",
              "      <th>number_of_jobs</th>\n",
              "      <th>area_size</th>\n",
              "      <th>no_of_houses</th>\n",
              "      <th>borough_flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>E09000001</td>\n",
              "      <td>city of london</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>33020.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>48922</td>\n",
              "      <td>0</td>\n",
              "      <td>6581.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>E09000002</td>\n",
              "      <td>barking and dagenham</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>21480.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23620</td>\n",
              "      <td>3</td>\n",
              "      <td>162444.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>E09000003</td>\n",
              "      <td>barnet</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>19568.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23128</td>\n",
              "      <td>8</td>\n",
              "      <td>313469.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>E09000004</td>\n",
              "      <td>bexley</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>18621.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21386</td>\n",
              "      <td>18</td>\n",
              "      <td>217458.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>E09000005</td>\n",
              "      <td>brent</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>18532.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20911</td>\n",
              "      <td>6</td>\n",
              "      <td>260317.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1066</th>\n",
              "      <td>K03000001</td>\n",
              "      <td>great britain</td>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>30446.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>37603</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1067</th>\n",
              "      <td>K04000001</td>\n",
              "      <td>england and wales</td>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>30500.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>37865</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1068</th>\n",
              "      <td>N92000002</td>\n",
              "      <td>northern ireland</td>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>27434.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32083</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1069</th>\n",
              "      <td>S92000003</td>\n",
              "      <td>scotland</td>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>30000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34916</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1070</th>\n",
              "      <td>W92000004</td>\n",
              "      <td>wales</td>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>27500.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31251</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1071 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-162941a5-ff50-4aad-9b06-335c19198b5b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-162941a5-ff50-4aad-9b06-335c19198b5b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-162941a5-ff50-4aad-9b06-335c19198b5b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           code                  area  ... no_of_houses  borough_flag\n",
              "0     E09000001        city of london  ...          NaN             1\n",
              "1     E09000002  barking and dagenham  ...          NaN             1\n",
              "2     E09000003                barnet  ...          NaN             1\n",
              "3     E09000004                bexley  ...          NaN             1\n",
              "4     E09000005                 brent  ...          NaN             1\n",
              "...         ...                   ...  ...          ...           ...\n",
              "1066  K03000001         great britain  ...          NaN             0\n",
              "1067  K04000001     england and wales  ...          NaN             0\n",
              "1068  N92000002      northern ireland  ...          NaN             0\n",
              "1069  S92000003              scotland  ...          NaN             0\n",
              "1070  W92000004                 wales  ...          NaN             0\n",
              "\n",
              "[1071 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuLewd421t_c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca2f4150-0860-4fe2-c8a8-89be3bb9e530"
      },
      "source": [
        "def get_year():\n",
        "  # add code below to return a new series created from the year column, with just years \n",
        "  #series_data = dataset['date']\n",
        "  year = dataset['date'].str.split(\"-\").str.get(0)\n",
        "  dataset[\"year\"] = year\n",
        "  \n",
        "  return(year)\n",
        "\n",
        "# run and test if returned series is of correct length and has correct first row \n",
        "\n",
        "actual_len = len(get_year())\n",
        "actual_value = get_year().iloc[0]\n",
        "expected_len = 1071\n",
        "expected_val = \"1999\"\n",
        "print(dataset)\n",
        "\n",
        "if actual_len == expected_len and actual_value == expected_val:\n",
        "  print(\"Test passed expected length 1071 and first value 1999 and got\", actual_len, actual_value)\n",
        "else: \n",
        "  print(\"Test failed expected length 1071 and first value 1999 and got length\", actual_len, \"value\", actual_value)\n"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           code                  area  ... borough_flag  year\n",
            "0     E09000001        city of london  ...            1  1999\n",
            "1     E09000002  barking and dagenham  ...            1  1999\n",
            "2     E09000003                barnet  ...            1  1999\n",
            "3     E09000004                bexley  ...            1  1999\n",
            "4     E09000005                 brent  ...            1  1999\n",
            "...         ...                   ...  ...          ...   ...\n",
            "1066  K03000001         great britain  ...            0  2019\n",
            "1067  K04000001     england and wales  ...            0  2019\n",
            "1068  N92000002      northern ireland  ...            0  2019\n",
            "1069  S92000003              scotland  ...            0  2019\n",
            "1070  W92000004                 wales  ...            0  2019\n",
            "\n",
            "[1071 rows x 13 columns]\n",
            "Test passed expected length 1071 and first value 1999 and got 1071 1999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPAgjR5U1utf"
      },
      "source": [
        "### Exercise 2\n",
        "---\n",
        "\n",
        "In exercise 1 you have extracted the year, but it's dtype is 'object' (it is still a string).  You can convert to integer by adding  .astype(int) to the daisychain.\n",
        "\n",
        "Create a new function called **get_int_year()**, `return` the year column with values of type int. \n",
        "\n",
        "**Test output**:  \n",
        "\n",
        "```\n",
        "...\n",
        "Name: year, Length: 1071, dtype: int64\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SuKrrvD2f1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d8ee993-6569-47e7-9c4f-f2370ffcbf33"
      },
      "source": [
        "def get_int_year():\n",
        "  # add code below to return a year column where values are of integer type\n",
        "  year = dataset['date'].str.split(\"-\").str.get(0).astype(int)\n",
        "  print(dataset)\n",
        "  return(year)\n",
        "\n",
        "# run and test if your returned series is of type int\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "actual = get_int_year().dtype\n",
        "expected = np.int64\n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed, expected\", expected, \"got\", actual)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           code                  area  ... borough_flag  year\n",
            "0     E09000001        city of london  ...            1  1999\n",
            "1     E09000002  barking and dagenham  ...            1  1999\n",
            "2     E09000003                barnet  ...            1  1999\n",
            "3     E09000004                bexley  ...            1  1999\n",
            "4     E09000005                 brent  ...            1  1999\n",
            "...         ...                   ...  ...          ...   ...\n",
            "1066  K03000001         great britain  ...            0  2019\n",
            "1067  K04000001     england and wales  ...            0  2019\n",
            "1068  N92000002      northern ireland  ...            0  2019\n",
            "1069  S92000003              scotland  ...            0  2019\n",
            "1070  W92000004                 wales  ...            0  2019\n",
            "\n",
            "[1071 rows x 13 columns]\n",
            "Test passed int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spoUBwxT2gSi"
      },
      "source": [
        "### Exercise 3\n",
        "---\n",
        "\n",
        "All the areas in the data set are in lower case.  To prepare the data for reporting, you may want to capitalise.  Use .str.title() to do this.\n",
        "\n",
        "Create the function **get_title_areas()** to do this. `Return` the newly capitalised area column "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fLUjUYk4AyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7b11ebf-6c99-43ed-820f-cb3650a0526d"
      },
      "source": [
        "def get_title_areas():\n",
        "  # add code below to capitalise the first letter of each string in the column 'area'\n",
        "  series_area = dataset['area']\n",
        "  area = series_area.str.title()\n",
        "  \n",
        "  return(area)\n",
        "\n",
        "# run and test if the first row of the area column is now correct \n",
        "\n",
        "actual = get_title_areas().iloc[0]\n",
        "expected = \"City Of London\"\n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed, expected\", expected, \"got\", actual)\n"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed City Of London\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuUQQF2a4CPX"
      },
      "source": [
        "### Exercise 4 - Filter all areas to find all with 'And' in the name\n",
        "---\n",
        "\n",
        "Create a function called **get_and()** which uses `str.contains()` and a search (e.g. df[df['area'].str.contains()]) to filter and `return` all areas with 'And' in the name  (Note:  case is important)\n",
        "\n",
        "**Test output**:  \n",
        "105 rows × 13 columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmT32YMq4BA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d3d5338-7eed-4381-8244-ec0e975bdddc"
      },
      "source": [
        "def get_and():\n",
        "# add code to return just rows in which area contains 'And'\n",
        "  area = dataset[dataset['area'].str.contains(\" and \", case=True)]\n",
        "  return(area)\n",
        "\n",
        "# run and test if returned is correct length \n",
        "\n",
        "actual = len(get_and())\n",
        "expected = 105\n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed, expected\", expected, \"got\", actual)"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed 105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ChmyffT7wDK"
      },
      "source": [
        "### Exercise 5\n",
        "---\n",
        "\n",
        "Filter the data for all areas starting with 'Ba'  \n",
        "\n",
        "*hint: use `startswith()`*\n",
        "\n",
        "**Test Ouput:**  \n",
        "42 rows, first row has area 'Barking and Dagenham'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li8sAN3O8Zxp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "866591b8-05ac-4516-fc11-37177d84d916"
      },
      "source": [
        "def get_ba():\n",
        "  # add code to filter for all areas starting with 'Ba' \n",
        "  filtered_dataset = dataset[dataset[\"area\"].str.startswith(\"ba\", na = True)]\n",
        " \n",
        "  return(filtered_dataset)\n",
        "\n",
        "# run and test if your returned rows are the right length \n",
        "\n",
        "actual = len(get_ba())\n",
        "expected = 42 \n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed, expected\", expected, \"got\", actual)\n"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrSsOstK8Z9_"
      },
      "source": [
        "### Exercise 6\n",
        "---\n",
        "Create function called **get_ham()** to filter and `return` the data for all areas ending with 'ham', for the year 2000\n",
        "\n",
        "*hint: use `endswith()`*   \n",
        "\n",
        "**Test output**:  \n",
        "4 rows (barking and dagenham, hammersmith and fulham, lewisham, newham)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMJckNo-ab3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bed3e5d5-6768-4680-e95e-a7d223e2517e"
      },
      "source": [
        "def get_ham():\n",
        "  # add code to return rows which end with 'ham' for the year 2000\n",
        "   filtered_dataset = dataset[dataset[\"area\"].str.endswith(\"ham\", na = True)]\n",
        "   by_2000 = filtered_dataset[filtered_dataset[\"year\"].str.contains(\"2000\")]\n",
        "   return(by_2000)\n",
        "  \n",
        "# run and test if correct number of rows are returned\n",
        "\n",
        "actual = len(get_ham())\n",
        "expected = 4 \n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed, expected\", expected, \"got\", actual)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_niKyF39X4q"
      },
      "source": [
        "### Exercise 7 - new data set\n",
        "---\n",
        "\n",
        "Use the data set here:  https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\n",
        "\n",
        "Read the data from the sheet 'Skill Migration'  \n",
        "\n",
        "Write a function called **create_new_df()** which will inspect the data, then create and return new dataframe with the following changes:\n",
        "\n",
        "1.  Remove the word 'Skills' from the 'skill_group_category' column   \n",
        "  *hint: you can use the `str.rstrip()` function*\n",
        "2.  Convert country_code to uppercase    \n",
        "  *hint: try `upper()`*  \n",
        "4.  Remove the skill_group_id and the wb_income columns\n",
        "3.  Filter for regions containing 'Asia'  \n",
        "  *hint: you might have to `return` it*\n",
        "\n",
        "**Test output**:  \n",
        "9969 rows × 10 columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\"\n",
        "\n",
        "def create_new_df():\n",
        "  # add code below to return a df with 'Skills' removed, country_code in uppercase, no skill_group_id or wb_income columns and only for regions containing Asia \n",
        "  df = pd.read_excel(url, sheet_name = \"Skill Migration\")\n",
        "  skills = df[\"skill_group_category\"].str.rstrip(\"Skills\")\n",
        "  df[\"skill_group_category\"] = skills\n",
        "  \n",
        "  return df\n",
        "\n",
        "new_df = create_new_df() \n",
        "new_df.columns\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtmBAu3DR75w",
        "outputId": "12611a57-fe12-4b29-a1b2-ae0a908d89b8"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['country_code', 'country_name', 'wb_income', 'wb_region',\n",
              "       'skill_group_id', 'skill_group_category', 'skill_group_name',\n",
              "       'net_per_10K_2015', 'net_per_10K_2016', 'net_per_10K_2017',\n",
              "       'net_per_10K_2018', 'net_per_10K_2019'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGfVBX1FCjZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ad64a41-8162-40e3-8324-a7cea3a43f7d"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\"\n",
        "\n",
        "def create_new_df():\n",
        "  # add code below to return a df with 'Skills' removed, country_code in uppercase, no skill_group_id or wb_income columns and only for regions containing Asia \n",
        "  df = pd.read_excel(url, sheet_name = \"Skill Migration\")\n",
        "  df[\"skill_group_category\"]= df[\"skill_group_category\"].str.rstrip(\"Skills\") # strip away the word Skills from the values in column Skill_group_category\n",
        "  \n",
        "\n",
        "  df['country_code'] = df['country_code'].str.upper() #changing country_code into upper case characters\n",
        "  \n",
        "  df = df.drop([\"skill_group_id\", \"wb_income\"], axis=1) #drop the two columns in [] from the df\n",
        "  \n",
        "  filtered_df = df[df['wb_region'].str.contains(\"Asia\", case=True)] #filter by region containing \"Asia\"\n",
        "\n",
        "  return filtered_df\n",
        "\n",
        "# run and test if returned dataframe is correct length, with the right number of columns  and first row skill_group_category is correct \n",
        "test_df = create_new_df()\n",
        "actual_len = len(test_df)\n",
        "actual_col = len(test_df.columns)\n",
        "expected_len = 9969\n",
        "expected_col = 10\n",
        "actual_skill = test_df['skill_group_category'].iloc[0]\n",
        "expected_skill = 'Tech '\n",
        "\n",
        "if actual_len == expected_len and actual_col == expected_col and actual_skill == expected_skill:\n",
        "  print(\"Test passed\", actual_len, \"x\", actual_col, actual_skill)\n",
        "else:\n",
        "  print(\"Test failed, expected\", expected_len, \"x\", expected_col, expected_skill, \"got\", actual_len, \"x\", actual_col, actual_skill)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed 9969 x 10 Tech \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_i4oQaoEKoY"
      },
      "source": [
        "### Exercise 8\n",
        "---\n",
        "\n",
        "Write a function called **clean_skills()** that will:\n",
        "1. rename the **net_per_10K_year** columns to be just the year\n",
        "2. in the **skill_group_category** column replace the 'z' in 'specialized' with 's' to Anglicise the spelling. \n",
        "\n",
        "The function should `return` the cleaned data.  \n",
        "\n",
        "Hint:  You can use the `replace()` function to replace substring's and characters in both column headings and the actual data.  \n",
        "* `.str.replace(\"old\",\"new\")`\n",
        "\n",
        "**Test output**:  \n",
        "17617 rows × 12 columns, with z replace by s in Specialized  \n",
        "Column names: country_code\tcountry_name\twb_income\twb_region\tskill_group_id\tskill_group_category\tskill_group_name\t2015\t2016\t2017\t2018\t2019"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEWS56l4JKx3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9197a334-91f4-4e20-80eb-bfaf264a0b26"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\"\n",
        "\n",
        "def create_new_df():\n",
        "  # add code below to return a df with 'Skills' removed, country_code in uppercase, no skill_group_id or wb_income columns and only for regions containing Asia \n",
        "  df = pd.read_excel(url, sheet_name = \"Skill Migration\")\n",
        "  df[\"skill_group_category\"]= df[\"skill_group_category\"].str.rstrip(\"Skills\") # strip away the word Skills from the values in column Skill_group_category\n",
        "  \n",
        "\n",
        "  df['country_code'] = df['country_code'].str.upper() #changing country_code into upper case characters\n",
        "  \n",
        "  df = df.drop([\"skill_group_id\", \"wb_income\"], axis=1) #drop the two columns in [] from the df\n",
        "  \n",
        "  filtered_df = df[df['wb_region'].str.contains(\"Asia\", case=True)] #filter by region containing \"Asia\"\n",
        "\n",
        "  return filtered_df\n",
        "\n",
        "filtered_df = create_new_df()\n",
        "\n",
        "def clean_skills():\n",
        "  #add code to anglicise Specialized in the skill category column\n",
        "  filtered_df[\"skill_group_category\"] = filtered_df[\"skill_group_category\"].str.replace(\"Specialized\",\"Specialised\")\n",
        "  \n",
        "  #rename the net_per_10K columns\n",
        "  x = filtered_df.rename(columns={\"net_per_10K_2015\": \"2015\", \"net_per_10K_2016\": \"2016\", \"net_per_10K_2017\": \"2017\", \"net_per_10K_2018\": \"2018\", \"net_per_10K_2019\": \"2019\"})\n",
        "\n",
        "  return x\n",
        "\n",
        "\n",
        "# run and test if columns have correct names and specialised is anglised \n",
        "test_df = clean_skills()\n",
        "test_df.info()\n",
        "if (test_df['skill_group_category'].str.contains('Specialised').any() == True) and (test_df.columns.str.contains('net_per_10K_').any() == False):\n",
        "  print(\"Test passed\")\n",
        "else:\n",
        "  print(\"Test failed\")\n"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 9969 entries, 0 to 17375\n",
            "Data columns (total 10 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   country_code          9969 non-null   object \n",
            " 1   country_name          9969 non-null   object \n",
            " 2   wb_region             9969 non-null   object \n",
            " 3   skill_group_category  9969 non-null   object \n",
            " 4   skill_group_name      9969 non-null   object \n",
            " 5   2015                  9969 non-null   float64\n",
            " 6   2016                  9969 non-null   float64\n",
            " 7   2017                  9969 non-null   float64\n",
            " 8   2018                  9969 non-null   float64\n",
            " 9   2019                  9969 non-null   float64\n",
            "dtypes: float64(5), object(5)\n",
            "memory usage: 856.7+ KB\n",
            "Test passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqc9I5VpJLpR"
      },
      "source": [
        "### Exercise 9\n",
        "---\n",
        "\n",
        "Read the 'Country Migration' sheet.\n",
        "\n",
        "Write a function that will:  \n",
        "*  convert the country codes to upper case  \n",
        "*  drop the lat and long columns for both base and target  \n",
        "*  rename the net_per_10K_year columns to year only  \n",
        "*  filter for base_country_wb_region contains 'Africa' and target_country_wb_region contains Asia  \n",
        "\n",
        "**Test output**:  \n",
        "```\n",
        "base_country_code\tbase_country_name\tbase_country_wb_income\tbase_country_wb_region\ttarget_country_code\ttarget_country_name\ttarget_country_wb_income\ttarget_country_wb_region\t2015\t2016\t2017\t2018\t2019\n",
        "0\tAE\tUnited Arab Emirates\tHigh Income\tMiddle East & North Africa\tAF\tAfghanistan\tLow Income\tSouth Asia\t0.19\t0.16\t0.11\t-0.05\t-0.02\n",
        "4\tAE\tUnited Arab Emirates\tHigh Income\tMiddle East & North Africa\tAM\tArmenia\tUpper Middle Income\tEurope & Central Asia\t0.10\t0.05\t0.03\t-0.01\t0.02\n",
        "5\tAE\tUnited Arab Emirates\tHigh Income\tMiddle East & North Africa\tAU\tAustralia\tHigh Income\tEast Asia & Pacific\t-1.06\t-3.31\t-4.01\t-4.58\t-4.09\n",
        "6\tAE\tUnited Arab Emirates\tHigh Income\tMiddle East & North Africa\tAT\tAustria\tHigh Income\tEurope & Central Asia\t0.11\t-0.08\t-0.07\t-0.05\t-0.16\n",
        "7\tAE\tUnited Arab Emirates\tHigh Income\tMiddle East & North Africa\tAZ\tAzerbaijan\tUpper Middle Income\tEurope & Central Asia\t0.24\t0.25\t0.10\t0.05\t0.04\n",
        "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
        "4132\tZM\tZambia\tLower Middle Income\tSub-Saharan Africa\tGB\tUnited Kingdom\tHigh Income\tEurope & Central Asia\t43.27\t27.60\t7.88\t6.90\t3.68\n",
        "4135\tZW\tZimbabwe\tLow Income\tSub-Saharan Africa\tAU\tAustralia\tHigh Income\tEast Asia & Pacific\t-1.31\t-2.33\t-2.10\t-2.08\t-1.84\n",
        "4138\tZW\tZimbabwe\tLow Income\tSub-Saharan Africa\tIS\tIceland\tHigh Income\tEurope & Central Asia\t8.52\t6.22\t2.35\t1.81\t0.97\n",
        "4142\tZW\tZimbabwe\tLow Income\tSub-Saharan Africa\tNO\tNorway\tHigh Income\tEurope & Central Asia\t2.88\t6.46\t2.10\t0.33\t-0.13\n",
        "4145\tZW\tZimbabwe\tLow Income\tSub-Saharan Africa\tGB\tUnited Kingdom\tHigh Income\tEurope & Central Asia\t3.91\t4.66\t0.74\t-0.66\t-1.97\n",
        "478 rows × 13 columns\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\"\n",
        "df = pd.read_excel(url, sheet_name = \"Country Migration\")\n",
        "\n",
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU68LOzmm2r6",
        "outputId": "cb579f58-4a5f-4787-d5e0-5853ea47aee0"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['base_country_code', 'base_country_name', 'base_lat', 'base_long',\n",
              "       'base_country_wb_income', 'base_country_wb_region',\n",
              "       'target_country_code', 'target_country_name', 'target_lat',\n",
              "       'target_long', 'target_country_wb_income', 'target_country_wb_region',\n",
              "       'net_per_10K_2015', 'net_per_10K_2016', 'net_per_10K_2017',\n",
              "       'net_per_10K_2018', 'net_per_10K_2019'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYu6n_jF9v1Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ad2ded-da11-4a57-d1ca-5b59f6bf431d"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\"\n",
        "\n",
        "def clean_country_mig():\n",
        "  # add code below to clean the data \n",
        "  df = pd.read_excel(url, sheet_name = \"Country Migration\")\n",
        "\n",
        "  df['base_country_code'] = df['base_country_code'].str.upper() #changing country_code into upper case characters\n",
        "  df['target_country_code'] = df['target_country_code'].str.upper() #changing country_code into upper case characters\n",
        "\n",
        "  df = df.drop(['base_lat', 'base_long','target_lat','target_long'], axis=1)\n",
        "  \n",
        "  df = df.rename(columns={\"net_per_10K_2015\": \"2015\", \"net_per_10K_2016\": \"2016\", \"net_per_10K_2017\": \"2017\", \"net_per_10K_2018\": \"2018\", \"net_per_10K_2019\": \"2019\"})\n",
        "  \n",
        "  base_df = df[df['base_country_wb_region'].str.contains(\"Africa\", case =True) ]#filter by base region containing \"Africa\"\n",
        "  filtered_df = base_df[base_df['target_country_wb_region'].str.contains(\"Asia\", case=True)] #filter by target region containing \"Asia\"\n",
        "  \n",
        "  return filtered_df\n",
        "\n",
        "\n",
        "# run test if there is the correct number of columns, country codes are in uppercase and year columns have been reformatted \n",
        "\n",
        "filtered_df = clean_country_mig()\n",
        "actual_col_len = len(filtered_df.columns)\n",
        "expected = 13\n",
        "\n",
        "print(filtered_df)\n",
        "\n",
        "if actual_col_len == expected and (filtered_df['base_country_code'].str.islower().any() == False) and (filtered_df.columns.str.contains('net_per_10K_').any() == False):\n",
        "  print(\"Test passed\")\n",
        "else:\n",
        "  print(\"Test failed\")"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     base_country_code     base_country_name  ...  2018  2019\n",
            "0                   AE  United Arab Emirates  ... -0.05 -0.02\n",
            "4                   AE  United Arab Emirates  ... -0.01  0.02\n",
            "5                   AE  United Arab Emirates  ... -4.58 -4.09\n",
            "6                   AE  United Arab Emirates  ... -0.05 -0.16\n",
            "7                   AE  United Arab Emirates  ...  0.05  0.04\n",
            "...                ...                   ...  ...   ...   ...\n",
            "4132                ZM                Zambia  ...  6.90  3.68\n",
            "4135                ZW              Zimbabwe  ... -2.08 -1.84\n",
            "4138                ZW              Zimbabwe  ...  1.81  0.97\n",
            "4142                ZW              Zimbabwe  ...  0.33 -0.13\n",
            "4145                ZW              Zimbabwe  ... -0.66 -1.97\n",
            "\n",
            "[478 rows x 13 columns]\n",
            "Test passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V6mNsfsNrsd"
      },
      "source": [
        "### Exercise 10\n",
        "---\n",
        "\n",
        "Read the data from file 'https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/titanic.csv'.\n",
        "\n",
        "Write a function that will return a new dataframe with just the married women listed, surname only.\n",
        "\n",
        "**Test output**:  \n",
        "```\n",
        "\tPassengerId\tSurvived\tPclass\tName\tSex\tAge\tSibSp\tParch\tTicket\tFare\tCabin\tEmbarked\n",
        "1\t2\t1\t1\tCumings\tfemale\t38.0\t1\t0\tPC 17599\t71.2833\tC85\tC\n",
        "3\t4\t1\t1\tFutrelle\tfemale\t35.0\t1\t0\t113803\t53.1000\tC123\tS\n",
        "8\t9\t1\t3\tJohnson\tfemale\t27.0\t0\t2\t347742\t11.1333\tNaN\tS\n",
        "9\t10\t1\t2\tNasser\tfemale\t14.0\t1\t0\t237736\t30.0708\tNaN\tC\n",
        "15\t16\t1\t2\tHewlett\tfemale\t55.0\t0\t0\t248706\t16.0000\tNaN\tS\n",
        "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
        "871\t872\t1\t1\tBeckwith\tfemale\t47.0\t1\t1\t11751\t52.5542\tD35\tS\n",
        "874\t875\t1\t2\tAbelson\tfemale\t28.0\t1\t0\tP/PP 3381\t24.0000\tNaN\tC\n",
        "879\t880\t1\t1\tPotter\tfemale\t56.0\t0\t1\t11767\t83.1583\tC50\tC\n",
        "880\t881\t1\t2\tShelley\tfemale\t25.0\t0\t1\t230433\t26.0000\tNaN\tS\n",
        "885\t886\t0\t3\tRice\tfemale\t39.0\t0\t5\t382652\t29.1250\tNaN\tQ\n",
        "129 rows × 12 columns\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4gx3RHIOczI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e31defd8-c927-48a8-e4b2-738560204396"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "titanic = \"https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/titanic.csv\"\n",
        "titanic = pd.read_csv(titanic)\n",
        "\n",
        "def get_married(df):\n",
        "  # add code to return only the last names of married women\n",
        "  filtered_df = df[df[\"Name\"].str.contains(\"Mrs\", case = True)]\n",
        "  surname_only = filtered_df[\"Name\"].str.split(\", \").str.get(0)\n",
        "  print(surname_only)\n",
        "  filtered_df[\"Name\"] = surname_only\n",
        "\n",
        "  return filtered_df\n",
        "\n",
        "# run and test if returned dataframe is correct length and has correct first row \n",
        "test_df = get_married(titanic)\n",
        "actual_len = len(test_df)\n",
        "expected_len = 129\n",
        "actual_name = test_df['Name'].iloc[0]\n",
        "expected_name = 'Cumings'\n",
        "\n",
        "if actual_len == expected_len and actual_name == expected_name:\n",
        "  print(\"Test passed, \", actual_len, actual_name)\n",
        "else:\n",
        "  print(\"Test failed expected \", expected_len, expected_name, \"got\", actual_len, actual_name)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1       Cumings\n",
            "3      Futrelle\n",
            "8       Johnson\n",
            "9        Nasser\n",
            "15      Hewlett\n",
            "         ...   \n",
            "871    Beckwith\n",
            "874     Abelson\n",
            "879      Potter\n",
            "880     Shelley\n",
            "885        Rice\n",
            "Name: Name, Length: 129, dtype: object\n",
            "Test passed,  129 Cumings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22Rhwx2Sb1Ey"
      },
      "source": [
        "---\n",
        "### Optional extra practice\n",
        "\n",
        "There are some similar and some more challenging exercises [here](https://www.w3resource.com/python-exercises/date-time-exercise/) if you would like to practice more. The site has its own editor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQV2NO8umBSk"
      },
      "source": [
        "# Reflection\n",
        "----\n",
        "\n",
        "## What skills have you demonstrated in completing this notebook?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUVvt2r0mCKq"
      },
      "source": [
        "Your answer: Lots of error message deciphering and asking for lots of help."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOrbWOuFmObq"
      },
      "source": [
        "## What caused you the most difficulty?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_eGng1GmO78"
      },
      "source": [
        "Your answer: For some reason this worksheet and the datetime one have given me the most trouble in terms of errors in syntax or not returning what I thoight I had asked for. I think I have finally gotten the hang of these methods but I will definitely need to refresh my memory from time to time."
      ]
    }
  ]
}