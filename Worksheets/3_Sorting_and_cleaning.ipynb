{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Sorting_and_cleaning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bjentwistle/PythonFundamentals/blob/main/Worksheets/3_Sorting_and_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CVoh0pMzW0l"
      },
      "source": [
        "# Sorting and cleaning \n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "In order to effectively analyse a dataset, often we need to prepare it first. \n",
        "Before a dataset is ready to be analysed we might need to:  \n",
        "\n",
        "* sort the data (can be a series or dataframe)  \n",
        "* remove any NaN values or drop NA values   \n",
        "* remove duplicate records (identical rows)  \n",
        "* normalise data in dataframe columns so that has a common scale [reference](https://towardsai.net/p/data-science/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff#:~:text=Similarly%2C%20the%20goal%20of%20normalization,dataset%20does%20not%20require%20normalization.&text=So%20we%20normalize%20the%20data,variables%20to%20the%20same%20range.)\n",
        "\n",
        "## Sorting the data  \n",
        "---\n",
        "\n",
        "\n",
        "Typically we want to sort data by the values in one or more columns in the dataframe  \n",
        "\n",
        "To sort the dataframe by series we use the pandas function **sort_values()**.  \n",
        "\n",
        "By default `sort_values()` sorts into ascending order.\n",
        "\n",
        "* sort by a single column e.g.\n",
        "  * `df.sort_values(\"Make\") `\n",
        "* sort by multiple columns e.g. \n",
        "  * `df.sort_values(by = [\"Model\", \"Make\"]) `\n",
        "    * this sorts by Model, then my Make \n",
        "* sort in *descending* order\n",
        "  * `df.sort_values(by = \"Make\", ascending = False)`\n",
        "  * `df.sort_values(by = [\"Make\", \"Model\"], ascending = False])`  \n",
        "\n",
        "Dataframes are mostly **immutable**, ie changes like sort_values do not change the dataframe permanently, they just change it for the time that the instruction is being used.\n",
        "\n",
        "`df.sort_values(by='Make')` *dataframe is now in sorted order and can be copied to a new dataframe*  \n",
        "`df_sorted_on_make` *original dataframe, df, will be as it was - unsorted* \n",
        "\n",
        "To **split** columns away from the dataframe after sorting, do this in the same instruction, e.g.:\n",
        "\n",
        "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]]`\n",
        "\n",
        "This sorts on Make and then Model in descending order, then splits off the Make and Model columns.\n",
        "\n",
        "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]].head()`\n",
        "\n",
        "This sorts on Make and then Model, then splits off the Make and Model columns and then splits off the first 5 rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANKknIx8E-hN"
      },
      "source": [
        "### Exercise 1 - get data, sort by happiness score \n",
        "---\n",
        "\n",
        "Read data into variable called **happiness** from the Excel file on Happiness Data at this link: https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\n",
        "\n",
        "Write a function called **sorted_rank** to display first 5 rows of data  \n",
        "\n",
        "The data is currently sorted by Happiness Rank...\n",
        "*  sort the data by Happiness Score in ascending order\n",
        "*  display sorted table\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\"\n",
        "df = pd.read_excel(url)\n",
        "df.columns\n",
        "\n"
      ],
      "metadata": {
        "id": "l75AVEdP8Wak",
        "outputId": "ceb4916e-26dc-4259-d7e6-7048a1cfb53d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Country', 'Region', 'Happiness Rank', 'Happiness Score',\n",
              "       'Standard Error', 'Economy (GDP per Capita)', 'Family',\n",
              "       'Health (Life Expectancy)', 'Freedom', 'Trust (Government Corruption)',\n",
              "       'Generosity', 'Dystopia Residual'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkvFGvJtHXiH",
        "outputId": "77083c09-0ba9-40fa-b823-e32037f55e05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "happiness = []\n",
        "\n",
        "def sorted_rank(df):\n",
        "# add code below to return a series sorted by Happiness Score in ascending order\n",
        "  url = \"https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\"\n",
        "  df = pd.read_excel(url)\n",
        "  happiness = df.sort_values(\"Happiness Score\")\n",
        "  return(happiness)\n",
        "\n",
        "# The code below will run and test your code to see if the first row of your series is correct \n",
        "actual = sorted_rank(happiness).index[0]\n",
        "expected = 157\n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Well done, test passed\")\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Well done, test passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_iomqRTH8LA"
      },
      "source": [
        "### Exercise 2 - sort by multiple columns, display the first 5 rows \n",
        "---\n",
        "\n",
        "Write a function called **get_gdp_health** which:\n",
        "\n",
        "1. sort the data by Economy (GDP per Capita) and Health (Life Expectancy) in ascending order \n",
        "2. display the first 5 rows of sorted data \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7XalX7OK0u-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f981ec28-d55c-4912-f46b-887aeb9526eb"
      },
      "source": [
        "def get_gdp_health():\n",
        "  # add code below to return a 5 row series which sorts rows by Economy and Health in ascending order \n",
        "  url = \"https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\"\n",
        "  df = pd.read_excel(url)\n",
        "  sorted_data = df.sort_values(by = [\"Economy (GDP per Capita)\", \"Health (Life Expectancy)\"])\n",
        "  return(sorted_data)\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# The code below will run and test your code to see if the first row of your series has the correct happiness score \n",
        "test = get_gdp_health()\n",
        "\n",
        "actual = test['Happiness Score'].iloc[0]\n",
        "expected = 4.517\n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Well done, test passed\")\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Country          Region  ...  Generosity  Dystopia Residual\n",
            "0  Switzerland  Western Europe  ...     0.29678            2.51738\n",
            "1      Iceland  Western Europe  ...     0.43630            2.70201\n",
            "2      Denmark  Western Europe  ...     0.34139            2.49204\n",
            "3       Norway  Western Europe  ...     0.34699            2.46531\n",
            "4       Canada   North America  ...     0.45811            2.45176\n",
            "\n",
            "[5 rows x 12 columns]\n",
            "Well done, test passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfQ3cys4LHNc"
      },
      "source": [
        "### Exercise 3 - sorting in descending order \n",
        "---\n",
        "\n",
        "Write a function called **get_descending** which will: \n",
        "\n",
        "Sort the data by Freedom and Trust (Government Corruption) in descending order and show the Country and Region only for the last five rows\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3haPVvX7MCom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd26919-9647-4d32-c6b2-2e545456ff48"
      },
      "source": [
        "def get_descending(df):\n",
        "  #add code below to return a series which contains the last 5 rows of Country and Region sorted by Freedom and Trust in descending order\n",
        "  url = \"https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\"\n",
        "  df = pd.read_excel(url)\n",
        "  sorted_descending = df.sort_values(by = [\"Freedom\", \"Trust (Government Corruption)\"], ascending = False)\n",
        "  return(sorted_descending.tail())\n",
        "\n",
        "#print(df[['Country', 'Region']].tail())\n",
        "\n",
        "\n",
        "# The code below will run and test your code to see if the length and series are correct \n",
        "actual = get_descending(happiness).index[0]\n",
        "expected = 136\n",
        "\n",
        "if actual == expected and (len(get_descending(happiness)) == 5):\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual, \"and length of series should have been 5 but was\", len(get_descending(happiness)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed 136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqnAoELjMDs7"
      },
      "source": [
        "# Cleaning the data\n",
        "\n",
        "Data comes from a range of sources:  forms, monitoring devices, etc.  There will often be missing values, duplicate records and values that are incorrectly formatted.  These can affect summary statistics and graphs plotted from the data.\n",
        "\n",
        "Techniques for data cleansing include:\n",
        "*  removing records with missing or null data (NaN, NA, \"\")\n",
        "*  removing duplicate rows (keeping just one, either the first or the last)\n",
        "\n",
        "Removal of rows according to criteria, or of columns are other ways that data might be cleaned up.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVqmfM5wk7NK"
      },
      "source": [
        "---\n",
        "\n",
        "## Removing NaN/Dropping NA values \n",
        "\n",
        "pandas have functions for checking a dataframe, or column, for null values, checking a column for missing values, and functions for dropping all rows that contain null values.\n",
        "\n",
        "* check for NA/NaN/missing values across dataframe (returns True if NA values exist)  \n",
        "  `df.isnull().values.any()`  \n",
        "\n",
        "* check for NA/NaN/missing values in specific column  \n",
        "  `df[\"column\"].isnull().values.any()`  \n",
        "\n",
        "* filter for non-null rows   \n",
        "  `df[~df[\"column\"].isnull()]`  \n",
        "  *hint: ~ means is not*\n",
        "\n",
        "* drop all rows that have NA/NaN values   \n",
        "  `df.dropna()`  \n",
        "\n",
        "* drop rows where NA/NaN values exist in specific columns  \n",
        "  `df.dropna(subset = [\"Make\", \"Model\"])`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC65hEZGOKNL"
      },
      "source": [
        "### Exercise 4 - check for null values \n",
        "---\n",
        "\n",
        "1. read data into a variable called **housing** from the file housing_in_london_yearly_variables.csv from this link: https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv \n",
        "\n",
        "Write a function called **check_null** which will:\n",
        "2. check if any NA values exist in the dataframe and print the result \n",
        "3. use df.info() to see which columns have null entries (*Hint: if the non-null count is less than total entries, column contains missing/NA entries*)  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7LYkXDNVVc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ab8e4b7-b328-4e2e-d7d1-f5b1e1113aec"
      },
      "source": [
        "housing = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "\n",
        "\n",
        "def check_null(df):\n",
        "  # add code below to return a bool statement for whether or not there are null values \n",
        "  df = pd.read_csv(housing)\n",
        "  return(df.isnull().values.any())\n",
        "\n",
        "df.info()\n",
        " \n",
        "# The code below will run and test your code to see if you are returning the correct answer\n",
        "actual = check_null(housing)\n",
        "expected = True\n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1071 entries, 0 to 1070\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   code               1071 non-null   object \n",
            " 1   area               1071 non-null   object \n",
            " 2   date               1071 non-null   object \n",
            " 3   median_salary      1049 non-null   float64\n",
            " 4   life_satisfaction  352 non-null    float64\n",
            " 5   mean_salary        1071 non-null   object \n",
            " 6   recycling_pct      860 non-null    object \n",
            " 7   population_size    1018 non-null   float64\n",
            " 8   number_of_jobs     931 non-null    float64\n",
            " 9   area_size          666 non-null    float64\n",
            " 10  no_of_houses       666 non-null    float64\n",
            " 11  borough_flag       1071 non-null   int64  \n",
            "dtypes: float64(6), int64(1), object(5)\n",
            "memory usage: 100.5+ KB\n",
            "Test passed True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJTecutIXFJM"
      },
      "source": [
        "### Exercise 5 - filter for non-null rows\n",
        "---\n",
        "\n",
        "Create function called **filter_null()** which filters the non-null rows by the `number_of_jobs` column. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fWi0_MLXEzY"
      },
      "source": [
        "def filter_null():\n",
        "  # add code below to filter out null values\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# The code below will run and test your code to see if the length of your returned dataframe is correct\n",
        "\n",
        "actual = len(filter_null())\n",
        "expected = 931 \n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed expected\", expected, \"got\", actual)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRBLm_bJVItu"
      },
      "source": [
        "### Exercise 5 - remove null values \n",
        "---\n",
        "Write a function called **drop_null** which will:\n",
        "1. remove rows with NA values for `life_satisfaction` (use [ ] even if only one column in list)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjZJNIC3QObK"
      },
      "source": [
        "def drop_null(df):\n",
        "  # add code which returns a dataframe with rows that contain NA values in the life_satisfaction column removed\n",
        "  \n",
        "\n",
        "\n",
        "# The code below will run and test your code to see if you have returned a series with the correct length and first row\n",
        "actual = drop_null(housing).index[0]\n",
        "expected = 613 \n",
        "\n",
        "if actual == expected and len(drop_null(housing)) == 352:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual, \"and length of series should have been 352 but was\", len(drop_null(housing))) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui8HF5z8SiK8"
      },
      "source": [
        "## Dropping duplicates\n",
        "---\n",
        "\n",
        "* To remove duplicate rows based on duplication of values in all columns  \n",
        "  `df.drop_duplicates()`  \n",
        "\n",
        "* To remove rows that have duplicate entries in a specified column  \n",
        "  `df.drop_duplicates(subset = ['Make'])`  \n",
        "\n",
        "* To remove rows that have duplicate entries in multiple columns  \n",
        "  `df.drop_duplicates(subset = ['Make', 'Model'])` \n",
        "\n",
        "* Remove duplicate rows keeping the last instance rather than the first (default):  \n",
        "  `df.drop_duplicates(keep='last')`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2Qf6uMxSb5t"
      },
      "source": [
        "### Exercise 6 - Removing duplicate entries \n",
        "---\n",
        "Write a function called **drop_duplicates** which will: \n",
        "\n",
        "remove duplicate `area` entries keeping first instance  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ8T0tYVQj74"
      },
      "source": [
        "def drop_duplicates(df):\n",
        "  # add code which returns a dataframe without duplicate area entries with first instance kept \n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "# The code below will run and test your code to see if you have returned a series with the correct length and first row\n",
        "actual = drop_duplicates(housing).index[0]\n",
        "expected = 0\n",
        "\n",
        "if actual == expected and len(drop_duplicates(housing)) == 51:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual, \"and length of series should have been 51 but was\", len(drop_duplicates(housing))) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQyytEbnZ1lw"
      },
      "source": [
        "# Reflection\n",
        "----\n",
        "\n",
        "## What skills have you demonstrated in completing this notebook?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM00hR5aZk1-"
      },
      "source": [
        "Your answer: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgexd27sZ1ly"
      },
      "source": [
        "## What caused you the most difficulty?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y_nrVBwaGXr"
      },
      "source": [
        "Your answer: "
      ]
    }
  ]
}